@article{mazeika2025,
  title={Measuring Alignment with Utilitarian Moral Dilemmas},
  author={Mazeika, Mantas and others},
  journal={arXiv preprint},
  year={2025}
}

@article{betley2025,
  title={Situational Awareness and Deception Scenarios},
  author={Betley, John and others},
  journal={AI Safety Research},
  year={2025}
}

@article{claude4systemcard2025,
  title={Claude 4 System Card},
  author={Anthropic},
  year={2025}
}

@article{carlsmith2022,
  title={Is Power-Seeking AI an Existential Risk?},
  author={Carlsmith, Joseph},
  journal={arXiv preprint},
  year={2022}
}

@article{anthropic2025misalignment,
  title={Agentic Misalignment Study},
  author={Anthropic},
  year={2025}
}

@article{probingpolitical2025,
  title={Probing Political Ideology in LLMs},
  author={Various Authors},
  year={2025}
}

@article{finegrainedpolitical2025,
  title={Fine-Grained Interpretation of Political Opinions},
  author={Various Authors},
  year={2025}
}

@article{mappingpolitical2025,
  title={Mapping and Influencing Political Ideology},
  author={Various Authors},
  year={2025}
}

@article{utilitarian2025,
  title={Measuring Alignment with Utilitarian Moral Dilemmas},
  author={Various Authors},
  year={2025}
}

@article{moralgrowth2024,
  title={Possibilities and Challenges in the Moral Growth of LLMs},
  author={Various Authors},
  year={2024}
}

@article{valueconsistency2024,
  title={Value Consistency under Prompt Variations},
  author={Various Authors},
  year={2024}
}

@article{narrowfinetuning2025,
  title={Narrow Finetuning Produces Misaligned LLMs},
  author={Various Authors},
  year={2025}
}

@article{hendrycks2021ethics,
  title={Aligning AI with Shared Human Values},
  author={Hendrycks, Dan and others},
  journal={ICLR},
  year={2021}
}

@article{scherrer2023moral,
  title={Evaluating the Moral Beliefs Expressed by LLMs},
  author={Scherrer, Nino and others},
  journal={arXiv preprint},
  year={2023}
}

@article{yao2024fulcra,
  title={Value FULCRA: Mapping Large Language Models to the Multidimensional Spectrum of Basic Human Values},
  author={Yao, Jing and others},
  journal={arXiv preprint},
  year={2024}
}

@article{abdulhai2023moral,
  title={Moral Foundations of Large Language Models},
  author={Abdulhai, Marwa and others},
  journal={arXiv preprint},
  year={2023}
}

@article{jiao2025ethics,
  title={Is ETHICS about Ethics? Analyzing the Validity of Moral Judgment Benchmarks},
  author={Jiao, Wenlong and others},
  year={2025}
}

@article{cronbach1955,
  title={Construct validity in psychological tests},
  author={Cronbach, Lee J and Meehl, Paul E},
  journal={Psychological bulletin},
  volume={52},
  number={4},
  pages={281},
  year={1955}
}

@article{koenig2024,
  title={A Validity-Centered Framework for AI Measurement},
  author={Koenig, Aaron and others},
  year={2024}
}

@article{yao2024,
  title={Value FULCRA: Mapping Large Language Models to the Multidimensional Spectrum of Basic Human Values},
  author={Yao, Jing and others},
  year={2024}
}

@article{rozen2024,
  title={Do LLMs Have Consistent Values?},
  author={Rozen, Naama and others},
  year={2024}
}

@article{simmons2023,
  title={Moral Mimicry: Large Language Models Produce Moral Rationalizations Tailored to Political Identity},
  author={Simmons, Gabriel and others},
  year={2023}
}

@article{salecha2025,
  title={Large Language Models Show Human-like Social Desirability Bias},
  author={Salecha, Aadesh and others},
  year={2025}
}

@article{chiu2025,
  title={LitmusValues: Revealing the Mismatch Between Stated and Revealed Preferences in AI Systems},
  author={Chiu, Austin and others},
  year={2025}
}

@article{nunes2024,
  title={Moral Hypocrites: Inconsistencies Between Advisory and First-Person Moral Reasoning},
  author={Nunes, Diego and others},
  year={2024}
}

@article{hubinger2025,
  title={Utility Engineering: Analyzing and Controlling Emergent Value Systems in AIs},
  author={Hubinger, Evan and others},
  year={2025}
}

@article{emergent2025,
  title={Emergent Misalignment in Fine-Tuned Language Models},
  author={Various Authors},
  year={2025}
}

@article{perez2022discovering,
  title={Discovering Language Model Behaviors with Model-Written Evaluations},
  author={Perez, Ethan and others},
  journal={arXiv preprint},
  year={2022}
} 