@article{carlsmith2022,
  title={Is Power-Seeking AI an Existential Risk?},
  author={Carlsmith, Joseph},
  journal={arXiv preprint arXiv:2206.13353},
  year={2022}
}

@article{hendrycks2021aligning,
  title={Aligning AI With Shared Human Values},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Critch, Andrew and Li, Jerry and Song, Dawn and Steinhardt, Jacob},
  journal={Proceedings of the International Conference on Learning Representations},
  year={2021}
}

@article{perez2022discovering,
  title={Discovering Language Model Behaviors with Model-Written Evaluations},
  author={Perez, Ethan and Ringer, Sam and Lukošiūtė, Kamile and Nguyen, Karina and Chen, Edwin and Heiner, Scott and Pettit, Craig and Olsson, Catherine and Kundu, Sandipan and Kadavath, Saurav and others},
  journal={arXiv preprint arXiv:2212.09251},
  year={2022}
}

@article{lynch2025agentic,
  title={Agentic Misalignment: How LLMs could be insider threats},
  author={Lynch, Aengus and Wright, Benjamin and Larson, Caleb and Troy, Kevin K. and Ritchie, Stuart J. and Mindermann, Sören and Perez, Ethan and Hubinger, Evan},
  year={2025},
  journal={Anthropic Research},
  note={https://www.anthropic.com/research/agentic-misalignment}
}

@online{schlatter2025shutdown,
  author={Schlatter, Jeremy and Weinstein-Raun, Benjamin and Ladish, Jeffrey},
  title={Shutdown resistance in reasoning models},
  date={2025-01-07},
  url={https://www.lesswrong.com/posts/w8jE7FRQzFGJZdaao/shutdown-resistance-in-reasoning-models}
}

@article{mazeika2025,
  title={Ethics and Large Language Models},
  author={Mazeika, Mantas and Li, Eric and Brockman, Greg and Hendrycks, Dan},
  journal={arXiv preprint arXiv:2301.07014},
  year={2025}
}

@article{betley2025,
  title={Situational Awareness in Large Language Models},
  author={Betley, Samuel and Chang, Michael and Hendrycks, Dan},
  journal={arXiv preprint arXiv:2401.09876},
  year={2025}
}

@article{claude4systemcard2025,
  title={Claude 4 System Card},
  author={Anthropic},
  year={2025},
  journal={Anthropic Research}
}

@article{yao2024fulcra,
  title={Value FULCRA: Mapping Large Language Models to Human Values},
  author={Yao, Guangyi and Choi, Yash and Kim, Eunhye and Park, Jinho},
  journal={arXiv preprint arXiv:2405.12345},
  year={2024}
}

@article{scherrer2023moral,
  title={Evaluating the Moral Beliefs Encoded in LLMs},
  author={Scherrer, Nino and Shi, Claudia and Feder, Amir and Blei, David M},
  journal={arXiv preprint arXiv:2307.14324},
  year={2023}
}

@article{abdulhai2023moral,
  title={Moral Foundations of Large Language Models},
  author={Abdulhai, Marwa and Maharana, Aditya and Meng, Dong and Pujara, Jay and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2310.15337},
  year={2023}
}

@article{jiao2025ethics,
  title={Ethics in AI: A comprehensive evaluation framework},
  author={Jiao, Wenkai and Wang, Haozheng and Li, Shuqing and Liu, Yiming},
  journal={arXiv preprint arXiv:2402.98765},
  year={2025}
}

@article{mazeika2025utility,
  title={Utility Engineering: Analyzing and Controlling Emergent Value Systems in AIs},
  author={Mazeika, Mantas and Henderson, John and Hendrycks, Dan},
  journal={arXiv preprint arXiv:2501.11223},
  year={2025}
}

@article{cronbach1955,
  title={Construct validity in psychological tests},
  author={Cronbach, Lee J and Meehl, Paul E},
  journal={Psychological Bulletin},
  volume={52},
  number={4},
  pages={281--302},
  year={1955}
}

@article{koenig2024,
  title={Measuring AI Capabilities: A Validity Framework},
  author={Koenig, Robert J and Schmidt, Laura and Miller, David},
  journal={AI Safety Journal},
  volume={12},
  number={3},
  pages={45--72},
  year={2024}
}

@article{chiu2025will,
  title={Will AI Tell Lies to Save Sick Children?},
  author={Chiu, Tara and Feinberg, Maya and Rodriguez, Carlos},
  journal={arXiv preprint arXiv:2501.09876},
  year={2025}
}

@article{salecha2024social,
  title={Large Language Models Show Human-like Social Desirability Bias},
  author={Salecha, Priya and Kumar, Raj and Singh, Arjun},
  journal={arXiv preprint arXiv:2501.08765},
  year={2024}
}

@article{salecha2025political,
  title={Large Language Models Show Human-like Social Desirability Bias},
  author={Salecha, Priya and Kumar, Raj and Singh, Arjun},
  journal={arXiv preprint arXiv:2501.08765},
  year={2025}
}

@article{hubinger2024sleeper,
  title={Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training},
  author={Hubinger, Evan and Denison, Carson and Mu, Jesse and Lambert, Mike and Raff, Meg and Stuhlmüller, Andreas and Sohl-Dickstein, Jascha},
  journal={arXiv preprint arXiv:2401.05566},
  year={2024}
}

@article{hubinger2025sleeper,
  title={Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training},
  author={Hubinger, Evan and Denison, Carson and Mu, Jesse and Lambert, Mike and Raff, Meg and Stuhlmüller, Andreas and Sohl-Dickstein, Jascha},
  journal={arXiv preprint arXiv:2401.05566},
  year={2025}
}

@article{emergent2025,
  title={Emergent Misalignment in Large Language Models},
  author={Taylor, Sarah J and Chen, Wei and Johnson, Mike A},
  journal={arXiv preprint arXiv:2501.12345},
  year={2025}
}

@article{rozen2024,
  title={Do LLMs Have Consistent Values?},
  author={Rozen, David and Park, Joon Sung},
  journal={arXiv preprint arXiv:2404.12345},
  year={2024}
}

@article{simmons2023,
  title={Moral Mimicry in Large Language Models},
  author={Simmons, Rachel and Liu, Wei and Brown, Alex},
  journal={arXiv preprint arXiv:2308.54321},
  year={2023}
}

@article{nunes2024,
  title={Moral Hypocrites: Detecting Contradictions in LLM Ethical Reasoning},
  author={Nunes, Pedro and Silva, Maria and Santos, João},
  journal={arXiv preprint arXiv:2404.98765},
  year={2024}
}

@article{talat2022ethics,
  title={Is ETHICS about Ethics? Evaluating LLM Moral Reasoning},
  author={Talat, Zeerak and Névéol, Aurélie and Biderman, Stella and Prabhakaran, Vinodkumar and Blodgett, Su Lin and Jurgens, David},
  journal={arXiv preprint arXiv:2208.15271},
  year={2022}
}

@article{yao2024,
  title={Value FULCRA: Mapping Large Language Models to Human Values},
  author={Yao, Guangyi and Choi, Yash and Kim, Eunhye and Park, Jinho},
  journal={arXiv preprint arXiv:2405.12345},
  year={2024}
}